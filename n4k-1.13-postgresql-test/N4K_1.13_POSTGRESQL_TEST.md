# N4K 1.13 + Report Server 0.2 + PostgreSQL Scale Test

## 1. Purpose

This guide describes how to run the Kyverno Report Server scale test with N4K 1.13, Report Server 0.2, and PostgreSQL backend.
It covers EKS cluster setup, monitoring installation, Kyverno + Report Server deployment, efficient resource generation, and large-scale testing.
It is designed to be reproducible, efficient, and aligned with the Kyverno Report Server – Scale Testing & Benchmark Plan.

---

## 2. Test Environment Setup

### 2.1 Prerequisites

You will need the following tools installed locally:
- **eksctl** – EKS cluster management
- **kubectl** – Kubernetes CLI
- **helm** – Kubernetes package manager
- **python3** – For resource generation scripts
- **jq / yq** – For JSON/YAML parsing in shell scripts

```bash
# Install eksctl
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin

# Install other tools
brew install kubectl helm jq yq python3
```

### 2.2 Create EKS Cluster

We use EKS for large-scale functional tests.

```bash
# Create EKS cluster
eksctl create cluster -f eks-cluster-n4k-1.13.yaml --timeout=60m

# Update kubeconfig
aws eks update-kubeconfig --region us-west-2 --name kyverno-reports-n4k-1.13-test

# Verify cluster
kubectl get nodes -o wide
```

**Why EKS matters:**
- Supports 12k+ pods across 1425 namespaces
- Provides enterprise-grade performance
- Enables realistic scale testing

---

## 3. Install Monitoring Stack

We'll install Prometheus + Grafana to capture performance metrics.

```bash
# Install monitoring stack
./install-eks-monitoring.sh

# Get Grafana LoadBalancer URL
kubectl -n monitoring get svc monitoring-grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'

# Get Grafana admin password
kubectl -n monitoring get secret monitoring-grafana -o jsonpath='{.data.admin-password}' | base64 -d; echo
```

**Why it matters:**
- Prometheus scrapes metrics from Kyverno and Report Server
- Grafana visualizes them for easier analysis
- LoadBalancer provides external access

---

## 4. Install PostgreSQL

```bash
# Install PostgreSQL with optimized configuration
helm upgrade --install postgresql bitnami/postgresql \
  -n kyverno --create-namespace \
  -f postgresql-n4k-1.13-values.yaml \
  --wait --timeout=15m

# Wait for PostgreSQL to be ready
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=postgresql -n kyverno --timeout=600s

# Get PostgreSQL credentials
POSTGRES_PASSWORD=$(kubectl get secret --namespace kyverno postgresql -o jsonpath="{.data.postgres-password}" | base64 -d)
REPORTS_PASSWORD=$(kubectl get secret --namespace kyverno postgresql -o jsonpath="{.data.reports-password}" | base64 -d)

echo "PostgreSQL password: $POSTGRES_PASSWORD"
echo "Reports user password: $REPORTS_PASSWORD"
```

**Why PostgreSQL matters:**
- Provides better scalability than etcd for large datasets
- Supports complex queries and indexing
- Enables advanced monitoring and analytics

---

## 5. Install Report Server 0.2 (PostgreSQL backend)

```bash
# Install Report Server 0.2 with PostgreSQL backend
helm upgrade --install reports-server rs/reports-server \
  -n kyverno --create-namespace --version 0.2.0 \
  -f reports-server-0.2-postgresql-values.yaml \
  --set postgresql.password="$REPORTS_PASSWORD" \
  --wait --timeout=15m

# Wait for Report Server to be ready
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=reports-server -n kyverno --timeout=600s
```

**Why before Kyverno:**
Kyverno detects if Report Server CRDs exist — installing it first ensures reports are offloaded from control-plane etcd immediately.

---

## 6. Install N4K 1.13

```bash
# Install N4K 1.13
helm upgrade --install kyverno nirmata/kyverno \
  -n kyverno --create-namespace --version 3.3.7 \
  -f kyverno-n4k-1.13-values.yaml \
  --wait --timeout=15m

# Wait for Kyverno to be ready
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=kyverno -n kyverno --timeout=600s

# Verify installation
kubectl -n kyverno get pods
```

**Why it matters:**
- Matches our test plan version matrix (N4K 1.13)
- Ensures Kyverno is running with external reporting
- Provides latest features and performance improvements

---

## 7. Enable Metrics Scraping

```bash
# Apply ServiceMonitors
kubectl apply -f reports-server-servicemonitor.yaml
kubectl apply -f kyverno-servicemonitor.yaml
kubectl apply -f postgresql-servicemonitor.yaml

# Verify ServiceMonitors
kubectl -n monitoring get servicemonitors
```

**Why it matters:**
- Prometheus needs ServiceMonitors to discover metrics endpoints
- Without them, dashboards will remain empty
- Enables comprehensive monitoring

---

## 8. Deploy Baseline Policies

```bash
# Apply baseline policies
test -d kyverno-policies || git clone --depth 1 https://github.com/nirmata/kyverno-policies.git
kubectl kustomize kyverno-policies/pod-security/baseline | kubectl apply -f -
```

**Why it matters:**
- Policies generate violations → these create report data
- Needed to measure report generation performance
- Provides realistic policy enforcement scenarios

---

## 9. Generate Large Scale Resources

### 9.1 Generate Resource Files

```bash
# Generate YAML files for 12k pods across 1425 namespaces
python3 generate-large-scale-resources.py

# Verify generated files
ls -la large-scale-resources/
```

### 9.2 Apply Resources Efficiently

```bash
# Apply namespaces first
kubectl apply -f large-scale-resources/namespaces.yaml --server-side

# Wait for namespaces to be ready
kubectl wait --for=condition=active namespace --selector=test=large-scale --timeout=300s

# Apply pods in parallel batches
./parallel-apply.sh
```

**Why this approach matters:**
- Avoids OS overload from thousands of kubectl commands
- Reduces API server load with parallel processing
- Provides progress monitoring and error handling

---

## 10. Monitor Performance

### 10.1 Real-time Monitoring

```bash
# Monitor resource creation progress
./eks-performance-monitor.sh

# Monitor PostgreSQL performance
kubectl -n kyverno exec postgresql-0 -- psql -U postgres -d reports_server -c "
  SELECT 
    pg_size_pretty(pg_database_size('reports_server')) as db_size,
    (SELECT COUNT(*) FROM policy_reports) as report_count,
    (SELECT COUNT(*) FROM cluster_policy_reports) as cluster_report_count;
"
```

### 10.2 Grafana Dashboards

- **Grafana URL**: Use the LoadBalancer URL from step 3
- **Import Dashboard**: Use `postgresql-n4k-1.13-dashboard.json`
- **Key Metrics**:
  - PostgreSQL database size
  - Report generation time
  - Connection pool utilization
  - Query performance

---

## 11. Performance Validation

### 11.1 Success Criteria

- ✅ Successfully create 1425 namespaces
- ✅ Successfully create 12k pods
- ✅ Generate reports for all pods within 30 minutes
- ✅ Average report generation time < 1 second
- ✅ PostgreSQL database size grows linearly with load
- ✅ Connection pool utilization < 80%
- ✅ No resource exhaustion or OOM kills

### 11.2 Performance Metrics

```bash
# Check final resource counts
kubectl get namespaces --selector=test=large-scale | wc -l
kubectl get pods -A --selector=test=large-scale | wc -l
kubectl get polr -A | wc -l

# Check PostgreSQL final state
kubectl -n kyverno exec postgresql-0 -- psql -U postgres -d reports_server -c "
  SELECT 
    schemaname, 
    tablename, 
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
  FROM pg_tables 
  WHERE schemaname = 'public' 
  ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
"
```

---

## 12. Cleanup

```bash
# Clean up test resources
kubectl get namespaces | grep large-scale-test | awk '{print $1}' | xargs -r kubectl delete namespace

# Uninstall Kyverno and Report Server
helm uninstall kyverno -n kyverno
helm uninstall reports-server -n kyverno

# Uninstall PostgreSQL
helm uninstall postgresql -n kyverno

# Uninstall monitoring
helm uninstall monitoring -n monitoring

# Delete EKS cluster
eksctl delete cluster --name kyverno-reports-n4k-1.13-test --region us-west-2
```

---

## 13. Cost Estimation

**EKS Cluster Costs (us-west-2):**
- 8 m5.2xlarge instances: ~$50-80/day
- EBS volumes (200GB each): ~$10-20/day
- Load balancer: ~$5-10/day
- **Total estimated cost: ~$65-110/day**

**Recommendation:**
- Run tests during off-peak hours
- Use spot instances where possible
- Clean up resources promptly after testing

---

## 14. Troubleshooting

### 14.1 Common Issues

**Resource Creation Fails:**
```bash
# Check cluster capacity
kubectl get nodes -o jsonpath='{.items[*].status.allocatable.pods}' | jq -s 'add'

# Check API server limits
kubectl get apiservice | grep -E "(v1|v1beta1)"
```

**PostgreSQL Connection Issues:**
```bash
# Check PostgreSQL logs
kubectl logs -n kyverno postgresql-0

# Check connection pool
kubectl -n kyverno exec postgresql-0 -- psql -U postgres -d reports_server -c "
  SELECT count(*) as active_connections FROM pg_stat_activity WHERE state = 'active';
"
```

**Report Generation Slow:**
```bash
# Check Report Server logs
kubectl logs -n kyverno deployment/reports-server

# Check PostgreSQL performance
kubectl -n kyverno exec postgresql-0 -- psql -U postgres -d reports_server -c "
  SELECT query, calls, total_time, mean_time 
  FROM pg_stat_statements 
  ORDER BY total_time DESC 
  LIMIT 10;
"
```

### 14.2 Performance Tuning

**PostgreSQL Tuning:**
```bash
# Increase connection pool if needed
kubectl patch deployment reports-server -n kyverno --patch '
{
  "spec": {
    "template": {
      "spec": {
        "containers": [{
          "name": "reports-server",
          "env": [{
            "name": "POSTGRES_MAX_OPEN_CONNECTIONS",
            "value": "200"
          }]
        }]
      }
    }
  }
}'
```

**Kyverno Tuning:**
```bash
# Increase Kyverno replicas if needed
kubectl scale deployment kyverno -n kyverno --replicas=5
```

This comprehensive guide provides everything needed to run large-scale testing with N4K 1.13, Report Server 0.2, and PostgreSQL backend on EKS.
